I"1<h2 id="adversarial-nets">Adversarial nets</h2>

<p>The adversarial modeling framework is most straightforward to apply when the models are both multilayer perceptrons. To learn the generatorâ€™s distribution \(p_{g}\) over data x, we define a prior on input noise variables \(p_{z}(z)\), then represent a mapping to data space as \(G(z; \theta_{g})\), where \(G\) is a differentiable function represented by a multilayer perceptron with parameters \(\theta_{g}\).</p>

<h2 id="objective-function">Objective Function</h2>

<p>[\min_{\theta_{g}}\max_{\theta_{d}}[\mathbb{E}<em>{x\sim p</em>{data}}\log D_{\theta_{d}} + \mathbb{E}<em>{z\sim p(z)} \log(1-D</em>{\theta_{d}}(G_{\theta_{g}}(z)))] \tag {1}\]</p>

<p>A game-theoretic approach is taken, this objective function is represented as a minimax function. The discriminator tries to maximize the objective function, therefore we can perform gradient ascent on the objective function. The generator tries to minimize the objective function, therefore we can perform gradient descent on the objective function. By alternating between gradient ascent and descent, the network can be trained.</p>

<p><strong>Gradient Ascent on Discriminator</strong></p>

<p>[\max_{\theta_{d}}[\mathbb{E}<em>{x\sim p</em>{data}}\log D_{\theta_{d}} + \mathbb{E}<em>{z\sim p(z)} \log(1-D</em>{\theta_{d}}(G_{\theta_{g}}(z)))]  \tag {2}\]</p>

<p><strong>Gradient Descent on Generator</strong></p>

<p>[\min_{\theta_{g}}[\mathbb{E}<em>{z\sim p(z)} \log(1-D</em>{\theta_{d}}(G_{\theta_{g}}(z)))] \tag{3}\]</p>

<p>But when applied, it is observed that optimizing the generator objective function does not work so well, because at the beginning of training G is very weak and D can discriminate fake data with high confidence, this lead the gradient for training G is very small(nearly 0 when using sigmoid activate function), G will be hard to train. This phenomenon is called gradient saturate.</p>

<p><strong>new Generator objective function</strong></p>

<p>[\max_{\theta_{g}} \mathbb{E}<em>{z\sim p(z)} \log (D</em>{\theta_{d}}(G_{\theta_{g}}(z))) \tag {4}\]</p>
:ET