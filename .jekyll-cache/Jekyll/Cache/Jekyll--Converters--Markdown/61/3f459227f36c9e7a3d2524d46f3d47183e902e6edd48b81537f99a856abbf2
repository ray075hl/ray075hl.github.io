I"ø/<h1 id="pytorch-data-loading-pipeline">Pytorch data loading pipeline</h1>
<p>There are three classes we will use to customize our own dataset pipeline on usual.</p>

<h2 id="dataset-class">Dataset class</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
</code></pre></div></div>
<p><strong>Dataset</strong> is an ablstract class representing a dataset. 
Custom dataset should inherit <strong>Dataset</strong> and override the following methods:</p>

<ul>
  <li><strong>_<em>len_</em></strong> so that <strong>len(dataset)</strong> returns the size of the dataset.</li>
  <li><strong>_<em>getitem_</em></strong> to support the indexing such that <strong>dataset[i]</strong> can be used to get
<strong>i th</strong> sample</li>
</ul>

<p>We using <strong>minist</strong> to explain this class</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">MnistDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root_dir_image</span><span class="p">,</span> <span class="n">root_dir_label</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="s">"""
        Args: 
            root_dir (string): Directory with all the images and labels.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """</span>
        <span class="s">"""
        Suppose data storage as follow: 1.jpg 2.jpg 3.jpg ...
                                        1.txt 2.txt 3.txt ...
        """</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">root_dir_image</span> <span class="o">=</span> <span class="n">root_dir_image</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">root_dir_label</span> <span class="o">=</span> <span class="n">root_dir_label</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">root_dir_image</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
        <span class="n">img_name</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">root_dir_image</span><span class="p">,</span> <span class="n">idx</span><span class="o">+</span><span class="s">'.jpg'</span><span class="p">)</span>
        <span class="n">label_name</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">root_dir_label</span><span class="p">,</span> <span class="n">idx</span><span class="o">+</span><span class="s">'.txt'</span><span class="p">)</span>
        
        <span class="n">image</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">img_name</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">label_name</span><span class="p">)</span>  <span class="c1"># assume already one hot encoded
</span>        
        <span class="n">sample</span> <span class="o">=</span> <span class="p">{</span><span class="s">'image'</span> <span class="p">:</span> <span class="n">image</span><span class="p">,</span> <span class="s">'label'</span> <span class="p">:</span> <span class="n">label</span><span class="p">}</span>
    
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">tranform</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">tranform</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="n">sample</span>
        
</code></pre></div></div>

<h2 id="dataloader-class">DataLoader class</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
</code></pre></div></div>
<p>Using <strong>MnistDataset</strong> to obtain just one sample each time. As training a neural network(NN)
, batching the input data can accelerate convergence of NN. <strong>DataLoader</strong> can deal with that.</p>

<ul>
  <li>Batching the data</li>
  <li>Shuffling the data</li>
  <li>Load the data in parallel using <strong>multiprocessing</strong> workers.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">minist_data</span> <span class="o">=</span> <span class="n">MnistDataset</span><span class="p">(</span><span class="s">'./images'</span><span class="p">,</span> <span class="s">'./label'</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">minist_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
                        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i_batch</span><span class="p">,</span> <span class="n">sample_batched</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">i_batch</span><span class="p">,</span> <span class="n">sample_batched</span><span class="p">[</span><span class="s">'image'</span><span class="p">].</span><span class="n">size</span><span class="p">().</span>
             <span class="n">sample_batched</span><span class="p">[</span><span class="s">'label'</span><span class="p">].</span><span class="n">size</span><span class="p">())</span>

</code></pre></div></div>

<h2 id="transforms-class">Transforms class</h2>
<p>Data argumentation will using this class in general.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">transform</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">utils</span>

<span class="s">"""
Using opencv and skimage to transform a image
for example.
"""</span>
<span class="k">class</span> <span class="nc">Recale</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="s">"""
    Recalse the image in a sample to a given size.
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="k">pass</span>
     
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
        <span class="k">pass</span>
        <span class="k">return</span> <span class="n">a_recale_sample</span>
        
<span class="k">class</span> <span class="nc">Crop</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>  
    <span class="s">"""
    Random crop a image
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="k">pass</span>
        
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
        <span class="k">pass</span>
        <span class="k">return</span> <span class="n">a_cropped_sample</span>


<span class="k">class</span> <span class="nc">ToTensor</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">pass</span>


<span class="s">"""
Intergate with Dataset class
"""</span>
<span class="n">scale</span> <span class="o">=</span> <span class="n">Recale</span><span class="p">(</span><span class="mi">224</span><span class="p">)</span>
<span class="n">crop</span> <span class="o">=</span> <span class="n">Crop</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
<span class="n">composed</span> <span class="o">=</span> <span class="n">tranform</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">Recale</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span> <span class="n">Crop</span><span class="p">(</span><span class="mi">200</span><span class="p">),</span> <span class="n">ToTensor</span><span class="p">()])</span>

<span class="n">transformed_minist_dataset</span> <span class="o">=</span> <span class="n">MnistDataset</span><span class="p">(</span><span class="s">'./images'</span><span class="p">,</span> <span class="s">'./label'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">composed</span><span class="p">)</span>
<span class="n">transformed_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">transformed_minist_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
                        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="reference">Reference</h2>
<p><a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html">Data Loading and Processing Tutorial</a></p>
:ET